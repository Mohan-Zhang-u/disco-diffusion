0: [
        "A scientist doing experiments that helps the innovation of human society. The experiment will be a great breakthrough in human history.",
        "I hate that time flies so fast and I only have a very short life. There are so many beautiful things in life but I can only live less than a hundred years.",
        "Prime numbers in turbulence.",
        "People creating the god.",
        "Spinning quantum, fiber bundle.",
        "Vectors supporting a coffee mug and donuts.",
        "A neural network that can distinguish cant and dog.",
        "The light in a lab enlightens a dark night.",
        "The complex canvas is filled with blank.",
        "Generations of scientists finally overcomes a difficulty and make a breakthrough in research.",
        "Meteors shine in the sky, seas change into farming lands.",        
    ],

intermediate_saves = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95]#@param{type: 'raw'}

retain_overwritten_frames = True #@param{type: 'boolean'}

TODO:

!!! most important one! steps = 250 #@param [25,50,100,150,250,500,1000]{type: 'raw', allow-input: true}, which is used to control diffusion_steps
steps: (250|50-10000) When creating an image, the denoising curve is subdivided into steps for processing. Each step (or iteration) involves the AI looking at subsets of the image called ‘cuts’ and calculating the ‘direction’ the image should be guided to be more like the prompt. Then it adjusts the image with the help of the diffusion denoiser, and moves to the next step.
Increasing steps will provide more opportunities for the AI to adjust the image, and each adjustment will be smaller, and thus will yield a more precise, detailed image.  Increasing steps comes at the expense of longer render times.  Also, while increasing steps should generally increase image quality, there is a diminishing return on additional steps beyond 250 - 500 steps.  However, some intricate images can take 1000, 2000, or more steps.  It is really up to the user.  
Just know that the render time is directly related to the number of steps, and many other parameters have a major impact on image quality, without costing additional time.
diffusion_steps: (leave at default) This is an internal variable that you should leave alone.  In future DD releases, this will likely be hidden from users, as it’s not meant to be edited directly.

cutn_batches: (4|1-8) Each iteration, the AI cuts the image into smaller pieces known as cuts, and compares each cut to the prompt to decide how to guide the next diffusion step.  More cuts can generally lead to better images, since DD has more chances to fine-tune the image precision in each timestep.  

use_secondary_model

The rough order of speed/mem usage is (smallest/fastest to largest/slowest):
VitB32 1
RN50 1
RN101
VitB16 1
RN50x4
RN50x16
RN50x64
ViTL14
For RN50x64 & ViTL14 you may need to use fewer cuts, depending on your VRAM.

timestep_respacing: (leave at default) This is an internal variable that you should leave alone.  In future DD releases, this will likely be hidden from users, as it’s not meant to be edited directly.

clip_guidance_scale: (5000|1500-100000) CGS is one of the most important parameters you will use. It tells DD how strongly you want CLIP to move toward your prompt each timestep.  Higher is generally better, but if CGS is too strong it will overshoot the goal and distort the image. So a happy medium is needed, and it takes experience to learn how to adjust CGS. 

